import os
from os.path import join
from pathlib import Path
from glob import glob
import numpy as np

import torch
from torch.utils.data import Dataset
from kits19cnn.io.preprocess import parse_slice_idx_to_str

class SliceDataset(Dataset):
    """
    Reads from a directory of 2D slice numpy arrays and samples positive
    slices. Assumes the data directory contains 2D slices processed by
    `io.Preprocessor.save_dir_as_2d()`.

    B (background), K (kidney), KT (kidney + tumor)
    Stage 1: Sampled each class with p=0.33
    Stage 2: Samples only K and KT (p=0.5)
    """
    def __init__(self, im_ids: np.array, pos_slice_dict: dict, transforms=None,
                 preprocessing=None, fg_classes=[0, 1, 2],
                 p_sampling: float = [0.33, 0.33, 0.34]):
        """
        Attributes
            im_ids (np.ndarray): of image names.
            pos_slice_dict (dict): dictionary generated by
                `io.Preprocessor.save_dir_as_2d()`
            transforms (albumentations.augmentation): transforms to apply
                before preprocessing. Defaults to HFlip and ToTensor
            preprocessing: ops to perform after transforms, such as
                z-score standardization. Defaults to None.
            p_sampling (list-like): sampling probabilities of classes
        """
        print(f"Assuming inputs are .npy files...")
        self.im_ids = im_ids
        self.pos_slice_dict = pos_slice_dict
        self.transforms = transforms
        self.preprocessing = preprocessing
        self.p_sampling = p_sampling
        self.fg_classes = fg_classes
        assert len(self.p_sampling) == 3, \
            "p_sampling must be length=3 because sampling all three classes"+ \
            " background, kidney, tumor"

    def __getitem__(self, idx):
        # loads data as a numpy arr and then adds the channel + batch size dimensions
        case_id = self.im_ids[idx]
        x, y = self.load_slices(case_id)

        if self.transforms:
            data_dict = self.transforms(image=x, mask=y)
            x, y = data_dict["image"], data_dict["mask"]

        if self.preprocessing:
            preprocessed = self.preprocessing(image=x, mask=y)
            x, y = preprocessed["image"], preprocessed["mask"]
        x = torch.from_numpy(x) if isinstance(x, np.ndarray) else x
        y = torch.from_numpy(y) if isinstance(y, np.ndarray) else y

        # squeeze to remove batch size dim
        x = torch.squeeze(x, dim=0).float()
        y = torch.squeeze(y, dim=0)

        return (x, y)

    def __len__(self):
        return len(self.im_ids)

    def load_slices(self, case_fpath):
        """
        Gets the slice idx using self.get_slice_idx_str() and actually loads
        the appropriate slice array.
        Loads the slices to the shape (1, 1, n, h, w).
        """
        slice_idx_str, _ = self.get_slice_idx_str(case_fpath)
        x_path = join(case_fpath, f"imaging_{slice_idx_str}.npy")
        y_path = join(case_fpath, f"segmentation_{slice_idx_str}.npy")
        return (np.load(x_path)[None, None], np.load(y_path)[None, None])

    def get_slice_idx_str(self, case_fpath):
        """
        Gets the slice idx and processes it so that it fits how the arrays
        were saved by `io.Preprocessor.save_dir_as_2d`.
        Returns:
            (slice index string version, raw integer slice index)
        """
        # extracting slice:
        slice_idx = self.get_raw_slice_idx(case_fpath)
        # else:
            # slice_idx = self.get_rand_slice_idx(case_fpath)
        slice_idx_str = parse_slice_idx_to_str(slice_idx)
        return (slice_idx_str, slice_idx)

    def get_raw_slice_idx(self, case_fpath):
        """
        Gets a random positive slice index from self.pos_slice_dict (that was
        generated by io.preprocess.Preprocessor when save_as_slices=True).
        Args:
            case_fpath: each element of self.im_ids (path to a case folder)
        Returns:
            an integer representing a random non-background class slice index
        """
        case_raw = Path(case_fpath).name
        # finding slice index from a randomly sampled class
        sampled_class = np.random.choice(self.fg_classes,
                                         p=self.p_sampling)
        slice_indices = self.pos_slice_dict[case_raw][sampled_class]
        coord = np.random.choice(slice_indices)
        return coord

    def get_rand_slice_idx(self, case_fpath):
        """
        Args:
            case_fpath: each element of self.im_ids (path to a case folder)
        Returns:
            A randomly selected slice index
        """
        # assumes that there are no other files in said directory with "imaging_"
        _slice_files = [file for file in os.listdir(case_fpath)
                        if file.startswith("imaging_")]
        return np.random.randint(0, len(_slice_files))

class PseudoSliceDataset(SliceDataset):
    """
    Reads from a directory of 2D slice numpy arrays and samples positive
    slices. Assumes the data directory contains 2D slices processed by
    `io.Preprocessor.save_dir_as_2d()`. Generates 2.5D outputs

    B (background), K (kidney), KT (kidney + tumor)
    Stage 1: Sampled each class with p=0.33
    Stage 2: Samples only K and KT (p=0.5)
    """
    def __init__(self, im_ids: np.array, pos_slice_dict: dict, transforms=None,
                 preprocessing=None, p_pos_per_sample: float = 0.33,
                 num_pseudo_slices=5):
        """
        Attributes
            im_ids (np.ndarray): of image names.
            pos_slice_dict (dict): dictionary generated by
                `io.Preprocessor.save_dir_as_2d()`
            transforms (albumentations.augmentation): transforms to apply
                before preprocessing. Defaults to HFlip and ToTensor
            preprocessing: ops to perform after transforms, such as
                z-score standardization. Defaults to None.
            p_pos_per_sample (float): probability at which to sample slices
                that contain foreground classes.
            num_pseudo_slices (int): number of pseudo 3D slices. Defaults to 1.
                1 meaning no pseudo slices. If it's greater than 1, it must
                be odd (even numbers above and below)
        """
        super().__init__(im_ids=im_ids, pos_slice_dict=pos_slice_dict,
                         transforms=transforms, preprocessing=preprocessing,
                         p_pos_per_sample=p_pos_per_sample, mode=mode,
                         num_classes=num_classes)
        self.num_pseudo_slices = num_pseudo_slices
        assert num_pseudo_slices % 2 == 1, \
            "`num_pseudo_slices` must be odd. i.e. 7 -> 3 above and 3 below"

    def load_slices(self, case_fpath):
        """
        Gets the slice idx using self.get_slice_idx_str() and actually loads
        the appropriate slice array. Returned arrays have shape:
            (batch_size, n_channels, h, w)
        for batchgenerators transforms.
        """
        center_slice_idx_str, center_slice_idx = self.get_slice_idx_str(case_fpath)
        total_num_slices = len(glob(join(case_fpath, "imaging_*.npy")))
        min = center_slice_idx - (self.num_pseudo_slices - 1) // 2
        max = center_slice_idx + (self.num_pseudo_slices - 1) // 2 + 1

        x_path = join(case_fpath, f"imaging_{center_slice_idx_str}.npy")
        y_path = join(case_fpath, f"segmentation_{center_slice_idx_str}.npy")
        center_x, center_y = np.load(x_path)[None, None], np.load(y_path)[None, None]

        if self.num_pseudo_slices == 1:
            return (center_x, center_y)
        elif self.num_pseudo_slices > 1:
            # total shape: (1, num_pseudo_slices, h, w)
            x_arr = np.zeros((1, self.num_pseudo_slices) + center_x.shape[2:])
            for idx, slice_idx in enumerate(range(min, max)):
                slice_idx_str = parse_slice_idx_to_str(slice_idx)
                x_path = join(case_fpath, f"imaging_{slice_idx_str}.npy")
                # loading slices if they exist
                if os.path.isfile(x_path):
                    x_arr[:, idx] = np.load(x_path)
            return (x_arr, center_y)
